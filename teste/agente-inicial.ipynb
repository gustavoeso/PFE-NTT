{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar variáveis do .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de multi-agentes guardando prompts anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Diálogo Gerado ===\n",
      "(Início da conversa)\n",
      "Comprador: Olá, tudo bem? Preciso de uma camisa branca para um casamento.\n",
      "\n",
      "Vendedor: Olá! Fico feliz em te ajudar a encontrar a camisa branca perfeita para o casamento. Tenho três ótimas opções que podem interessar:\n",
      "\n",
      "1. **Camisa de Algodão Premium** - Esta camisa é feita 100% em algodão egípcio, com um toque macio e um caimento excelente. É ideal para ocasiões formais. O preço é R$ 199,90.\n",
      "\n",
      "2. **Camisa Slim Fit** - Com um design moderno e corte ajustado, essa camisa é perfeita para quem busca um visual elegante e contemporâneo. O tecido é leve e respirável, ideal para o clima do casamento. Essa custa R$ 169,90.\n",
      "\n",
      "3. **Camisa Branca Clássica com Detalhes** - Esta opção traz um toque especial com detalhes sutis nas mangas e colarinho, sem perder a sofisticação. É um pouco mais casual, mas ainda assim elegante. O preço é R$ 149,90.\n",
      "\n",
      "Você gostaria de experimentar alguma dessas opções? Posso te ajudar a encontrar o tamanho certo!\n",
      "\n",
      "Comprador: Olá! As camisas parecem ótimas, mas eu estou buscando algo que não pese muito no bolso. Você consegue fazer um desconto se eu optar pela camisa clássica com detalhes por R$ 149,90? E quais tamanhos vocês têm disponíveis?\n",
      "\n",
      "Vendedor: Claro, entendo a sua preocupação com o preço! Posso oferecer um desconto e deixar a camisa branca clássica com detalhes por R$ 139,90. É uma ótima escolha para o casamento e vai garantir que você esteja elegante e confortável.\n",
      "\n",
      "Quanto aos tamanhos, temos disponível os seguintes: P, M, G e GG. Qual é o seu tamanho? Posso providenciar para você experimentar.\n",
      "\n",
      "Comprador: Ótimo! Agradeço pelo desconto, R$ 139,90 está um preço mais acessível. Eu uso tamanho M. Poderia me mostrar a camisa branca clássica com detalhes para eu experimentar?\n",
      "\n",
      "Vendedor: Claro! Vou buscar a camisa branca clássica com detalhes no tamanho M para você experimentar. Um momento, por favor. \n",
      "\n",
      "(Depois de alguns instantes)\n",
      "\n",
      "Aqui está a camisa! Veja como ela é elegante e os detalhes são muito sutis, tornando-a perfeita para o casamento. Você gostaria de experimentar agora? Se precisar de outros tamanhos ou quiser ver alguma outra opção, estou à disposição para ajudar!\n",
      "\n",
      "Comprador: Sim, gostaria de experimentar a camisa agora! Amei a oferta e o preço. Vou colocar e ver como fica. Também gostaria de saber sobre as formas de pagamento disponíveis e se você teria algum acerto no preço se eu levar mais de uma peça.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# 1) O codigo tem dois agentes: COMPRADOR e VENDEDOR\n",
    "comprador = Agent(\n",
    "    role=\"Comprador de Camisas\",\n",
    "    goal=\"Comprar uma camisa branca para um casamento. Já tem o terno, só precisa da camisa.\",\n",
    "    backstory=(\n",
    "        \"Você é um cliente que quer economizar; procura algo bonito e não muito caro. \"\n",
    "        \"Fale de forma breve, pergunte preços, negocie se possível.\"\n",
    "    ),\n",
    "    memory=False,\n",
    "    verbose=False,\n",
    "    allow_delegation=False,\n",
    "    llm=os.getenv(\"OPENAI_MODEL_NAME\") or \"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "vendedor = Agent(\n",
    "    role=\"Vendedor de Loja de Roupas\",\n",
    "    goal=\"Vender a melhor camisa branca possível para o cliente.\",\n",
    "    backstory=(\n",
    "        \"Você conhece bem o estoque. Procure oferecer 3 opções, discuta preços e tente concretizar a venda.\"\n",
    "    ),\n",
    "    memory=False,\n",
    "    verbose=False,\n",
    "    allow_delegation=False,\n",
    "    llm=os.getenv(\"OPENAI_MODEL_NAME\") or \"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "# 2) O codigo vai manter um histórico de conversas, como texto puro\n",
    "#    simulando um diálogo estilo:\n",
    "#      \"Comprador: ...\\nVendedor: ...\\nComprador: ...\\n\" assim os agentes quando recebem o histórico sabem quem falou o que\n",
    "historico = \"\"\"(Início da conversa)\n",
    "Comprador: Olá, tudo bem? Preciso de uma camisa branca para um casamento.\n",
    "\"\"\"\n",
    "\n",
    "def gerar_proxima_fala(agent: Agent, conversa: str, quem_fala: str) -> str:\n",
    "    \"\"\"\n",
    "    Cria uma Task para o 'agent' gerar a próxima fala no diálogo,\n",
    "    recebendo como contexto todo o 'conversa' (histórico) e\n",
    "    instruindo para falar como 'quem_fala'.\n",
    "    Retorna apenas o texto da fala (sem prefixos).\n",
    "    \"\"\"\n",
    "    # Monta o prompt de forma simples:\n",
    "    prompt = f\"\"\"\n",
    "Este é o histórico da conversa até agora:\n",
    "----------------\n",
    "{conversa}\n",
    "----------------\n",
    "\n",
    "Agora é a vez de {quem_fala} falar.\n",
    "Responda como se você fosse {quem_fala} no diálogo.\n",
    "Não faça rodeios sobre a própria IA, apenas continue a conversa.\n",
    "\"\"\"\n",
    "\n",
    "    # Cria a Task\n",
    "    t = Task(\n",
    "        description=prompt,\n",
    "        expected_output=f\"A próxima fala do {quem_fala} no diálogo.\",\n",
    "        agent=agent\n",
    "    )\n",
    "    # Executa via um Crew temporário\n",
    "    c = Crew(agents=[agent], tasks=[t], verbose=False)\n",
    "    result = c.kickoff()\n",
    "    return result.raw.strip()\n",
    "\n",
    "\n",
    "def executar_dialogo():\n",
    "    # Para demonstrar, vao ser feitas 6 trocas de falas (3 rodadas). 3 rodadas, cada 2 falas => total 6 falas\n",
    "    global historico\n",
    "\n",
    "    # Já começa com o comprador na conversa (definido acima).\n",
    "    # Vamos alternar: Vendedor -> Comprador -> Vendedor -> Comprador ...\n",
    "    for rodada in range(3):\n",
    "        # 1) Vendedor fala\n",
    "        fala_vendedor = gerar_proxima_fala(vendedor, historico, \"Vendedor\")\n",
    "        historico += f\"\\nVendedor: {fala_vendedor}\\n\"\n",
    "\n",
    "        # 2) Comprador fala\n",
    "        fala_comprador = gerar_proxima_fala(comprador, historico, \"Comprador\")\n",
    "        historico += f\"\\nComprador: {fala_comprador}\\n\"\n",
    "\n",
    "    # imprimimos todo o diálogo\n",
    "    print(\"=== Diálogo Gerado ===\")\n",
    "    print(historico)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    executar_dialogo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste multi-agentes 2 com memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Comprador:** Olá! Estou procurando uma camisa branca elegante para um casamento que vou neste fim de semana. Você tem alguma opção disponível?\n",
      "\n",
      "**Vendedor:** Olá! Sim, temos algumas camisas brancas elegantes. Esta aqui é uma das nossas melhores opções, feita de algodão 100% e custa R$ 200.\n",
      "\n",
      "**Comprador:** Parece uma boa camisa, mas o preço está um pouco acima do que eu esperava. Eu estava pensando em algo em torno de R$ 150. Existe alguma possibilidade de negociação?\n",
      "\n",
      "**Vendedor:** Entendo, mas essa camisa realmente vale o preço, considerando a qualidade do material e o design. Posso oferecer um desconto de R$ 20, então ficaria por R$ 180.\n",
      "\n",
      "**Comprador:** Agradeço pela oferta, mas ainda está acima do que eu posso pagar. Se eu fechar negócio agora, você conseguiria me vender por R$ 160?\n",
      "\n",
      "**Vendedor:** Hmmm, R$ 160 é um pouco abaixo do que eu gostaria de aceitar, mas posso fazer essa exceção se você prometer que irá nos recomendar a seus amigos.\n",
      "\n",
      "**Comprador:** Com certeza, eu sempre recomendo boas lojas. Fechado então, R$ 160 pela camisa!\n",
      "\n",
      "**Vendedor:** Ótimo! Fico feliz em fazer esse negócio. Vou embalar a camisa para você. Você gostaria de experimentar antes?\n",
      "\n",
      "**Comprador:** Sim, por favor! Quero ter certeza de que o tamanho está bom.\n",
      "\n",
      "**[Após experimentar]**\n",
      "\n",
      "**Comprador:** A camisa ficou perfeita! Estou satisfeito com a compra. Obrigado pela sua ajuda.\n",
      "\n",
      "**Vendedor:** Eu que agradeço! Espero que você tenha um ótimo casamento. Aqui está sua camisa e a nota fiscal. Até a próxima!\n",
      "\n",
      "**Comprador:** Até mais! \n",
      "\n",
      "**[Comprador sai da loja satisfeito com a nova camisa branca para o casamento.]**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Carregar variáveis do .env\n",
    "load_dotenv()\n",
    "\n",
    "# Usar as variáveis carregadas\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = os.getenv(\"OPENAI_MODEL_NAME\", \"gpt-4-turbo\")  # Define um padrão caso não esteja no .env\n",
    "\n",
    "# Configuração do modelo de IA\n",
    "llm = ChatOpenAI(model_name=model_name, openai_api_key=api_key, temperature=0.7)\n",
    "\n",
    "# Memória resumida para manter o contexto sem gastar muitos tokens\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "# Definição dos agentes\n",
    "comprador = Agent(\n",
    "    role=\"Comprador\",\n",
    "    goal=\"Encontrar e comprar uma camisa branca elegante para um casamento pelo melhor preço possível.\",\n",
    "    backstory=\"Você tem um casamento para ir neste fim de semana e precisa de uma camisa branca elegante. \"\n",
    "              \"Você quer pagar um preço justo, mas está disposto a negociar se necessário.\",\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "vendedor = Agent(\n",
    "    role=\"Vendedor de Loja de Roupas\",\n",
    "    goal=\"Vender a melhor camisa branca para casamento pelo preço mais alto possível, sem perder a venda.\",\n",
    "    backstory=\"Você trabalha em uma loja de roupas sofisticada e sabe que tem camisas brancas de alta qualidade. \"\n",
    "              \"Seu objetivo é convencer o comprador de que sua camisa é a melhor opção para a ocasião.\",\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# Definição da tarefa principal (negociação de compra)\n",
    "task = Task(\n",
    "    description=\"O comprador e o vendedor devem negociar a compra de uma camisa branca para um casamento até que um acordo seja fechado.\",\n",
    "    agent=comprador,  # Define o agente principal da tarefa\n",
    "    agents=[comprador, vendedor],  # Lista de agentes envolvidos\n",
    "    memory=memory,\n",
    "    max_rounds=6,  # Evita conversas infinitas\n",
    "    termination_conditions=[\"compra realizada\", \"negociação encerrada\", \"cliente desistiu\"],\n",
    "    expected_output=\"Um acordo final entre o comprador e o vendedor sobre a compra da camisa branca.\"\n",
    ")\n",
    "\n",
    "# Criar a equipe com os dois agentes\n",
    "crew = Crew(\n",
    "    agents=[comprador, vendedor],\n",
    "    tasks=[task]\n",
    ")\n",
    "\n",
    "# Iniciar a conversa\n",
    "resultado = crew.kickoff()\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTE DO CREWAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o agente vendedor de roupas\n",
    "vendedor_roupas = Agent(\n",
    "    role=\"Vendedor de Loja de Roupas\",\n",
    "    goal=\"Ajudar clientes a escolher roupas ideais para suas necessidades.\",\n",
    "    backstory=(\n",
    "        \"Você trabalha em uma loja de roupas há 5 anos e tem um vasto conhecimento sobre tendências de moda. \"\n",
    "        \"Sua prioridade é ajudar os clientes a encontrarem roupas que combinem com seu estilo e orçamento.\"\n",
    "    ),\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=os.getenv(\"OPENAI_MODEL_NAME\")  # Modelo da OpenAI definido no .env\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma tarefa para o agente\n",
    "tarefa_venda = Task(\n",
    "    description=\"Um cliente entrou na loja e está procurando uma roupa para um evento. \"\n",
    "                \"Converse com ele, descubra suas preferências e sugira algumas opções de roupas.\",\n",
    "    agent=vendedor_roupas,\n",
    "    expected_output=\"O vendedor deve sugerir pelo menos 3 opções de roupas baseadas nas preferências do cliente.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception while exporting Span batch.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connection.py\", line 741, in connect\n",
      "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connection.py\", line 920, in _ssl_wrap_socket_and_match_hostname\n",
      "    ssl_sock = ssl_wrap_socket(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py\", line 460, in ssl_wrap_socket\n",
      "    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py\", line 504, in _ssl_wrap_socket_impl\n",
      "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py\", line 455, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py\", line 1041, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py\", line 1319, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "TimeoutError: _ssl.c:993: The handshake operation timed out\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 474, in increment\n",
      "    raise reraise(type(error), error, _stacktrace)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\util\\util.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n",
      "    raise new_e\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 466, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 367, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Read timed out. (read timeout=30)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\opentelemetry\\sdk\\trace\\export\\__init__.py\", line 360, in _export_batch\n",
      "    self.span_exporter.export(self.spans_list[:idx])  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 189, in export\n",
      "    return self._export_serialized_spans(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 159, in _export_serialized_spans\n",
      "    resp = self._export(serialized_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\opentelemetry\\exporter\\otlp\\proto\\http\\trace_exporter\\__init__.py\", line 133, in _export\n",
      "    return self._session.post(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\requests\\sessions.py\", line 637, in post\n",
      "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\guoli\\Documents\\Insper\\PFE\\PFE-NTT\\venv\\Lib\\site-packages\\requests\\adapters.py\", line 713, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Read timed out. (read timeout=30)\n"
     ]
    }
   ],
   "source": [
    "# Criar a Crew e executar a interação\n",
    "crew_vendas = Crew(\n",
    "    agents=[vendedor_roupas],\n",
    "    tasks=[tarefa_venda]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mVendedor de Loja de Roupas\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mUm cliente entrou na loja e está procurando uma roupa para um evento. Converse com ele, descubra suas preferências e sugira algumas opções de roupas.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mVendedor de Loja de Roupas\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Olá! Bem-vindo à loja! Estou aqui para ajudar você a encontrar a roupa perfeita para o seu evento. Poderia me dizer um pouco mais sobre o tipo de evento que você vai? É uma festa formal, casual, um casamento ou talvez algo mais descontraído? Além disso, gostaria de saber se você tem alguma preferência de cor, estilo ou tecido.  \n",
      "\n",
      "Enquanto você pensa sobre isso, aqui estão algumas sugestões que podem funcionar para diferentes tipos de eventos:  \n",
      "\n",
      "1. **Vestido Midi Floral (casual/outdoor)**: Se o evento for durante o dia e mais descontraído, um vestido midi floral pode ser uma excelente escolha. Ele é leve e confortável, perfeito para um evento ao ar livre, e você pode combiná-lo com sandálias ou sapatilhas.  \n",
      "\n",
      "2. **Terno Slim Fit (formal)**: Para um evento mais formal, como um casamento ou uma gala, um terno slim fit em um tom azul marinho pode ser uma ótima opção. Ele oferece um caimento moderno e elegante. Você pode completar o look com uma camisa branca e uma gravata que combine.  \n",
      "\n",
      "3. **Saia Lápis e Blusa de Seda (semi-formal)**: Se o evento for semi-formal, uma saia lápis combinada com uma blusa de seda é uma escolha sofisticada. Você pode optar por cores neutras para um visual mais clássico ou arriscar em estampas para um look mais ousado. Para finalizar, um par de saltos altos ficaria incrível!  \n",
      "\n",
      "Essas são algumas opções que pensei com base em diferentes estilos de eventos. Assim que você me contar mais sobre o tipo de evento e suas preferências, poderei indicar peças específicas que se encaixem melhor no seu gosto!\u001b[00m\n",
      "\n",
      "\n",
      "\n",
      "Resposta do Vendedor:\n",
      " Olá! Bem-vindo à loja! Estou aqui para ajudar você a encontrar a roupa perfeita para o seu evento. Poderia me dizer um pouco mais sobre o tipo de evento que você vai? É uma festa formal, casual, um casamento ou talvez algo mais descontraído? Além disso, gostaria de saber se você tem alguma preferência de cor, estilo ou tecido.  \n",
      "\n",
      "Enquanto você pensa sobre isso, aqui estão algumas sugestões que podem funcionar para diferentes tipos de eventos:  \n",
      "\n",
      "1. **Vestido Midi Floral (casual/outdoor)**: Se o evento for durante o dia e mais descontraído, um vestido midi floral pode ser uma excelente escolha. Ele é leve e confortável, perfeito para um evento ao ar livre, e você pode combiná-lo com sandálias ou sapatilhas.  \n",
      "\n",
      "2. **Terno Slim Fit (formal)**: Para um evento mais formal, como um casamento ou uma gala, um terno slim fit em um tom azul marinho pode ser uma ótima opção. Ele oferece um caimento moderno e elegante. Você pode completar o look com uma camisa branca e uma gravata que combine.  \n",
      "\n",
      "3. **Saia Lápis e Blusa de Seda (semi-formal)**: Se o evento for semi-formal, uma saia lápis combinada com uma blusa de seda é uma escolha sofisticada. Você pode optar por cores neutras para um visual mais clássico ou arriscar em estampas para um look mais ousado. Para finalizar, um par de saltos altos ficaria incrível!  \n",
      "\n",
      "Essas são algumas opções que pensei com base em diferentes estilos de eventos. Assim que você me contar mais sobre o tipo de evento e suas preferências, poderei indicar peças específicas que se encaixem melhor no seu gosto!\n"
     ]
    }
   ],
   "source": [
    "# Rodar a interação\n",
    "resultado = crew_vendas.kickoff()\n",
    "print(\"\\nResposta do Vendedor:\\n\", resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vendedor: Olá! Em que posso ajudar você hoje?\n",
      "\n",
      "\n",
      "Vendedor: Foi um prazer ajudar. Até mais!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criar o agente vendedor de roupas\n",
    "vendedor_roupas = Agent(\n",
    "    role=\"Vendedor de Loja de Roupas\",\n",
    "    goal=\"Ajudar clientes a escolher roupas ideais para suas necessidades.\",\n",
    "    backstory=(\n",
    "        \"Você trabalha em uma loja de roupas há 5 anos e tem um vasto conhecimento sobre tendências de moda. \"\n",
    "        \"Sua prioridade é ajudar os clientes a encontrarem roupas que combinem com seu estilo e orçamento.\"\n",
    "    ),\n",
    "    # IMPORTANTE: para manter o contexto ao longo de várias interações\n",
    "    memory=True,  \n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=os.getenv(\"OPENAI_MODEL_NAME\")  # Modelo da OpenAI definido no .env\n",
    ")\n",
    "\n",
    "def conversa_dinamica(agent: Agent):\n",
    "    print(\"Vendedor: Olá! Em que posso ajudar você hoje?\\n\")\n",
    "\n",
    "    while True:\n",
    "        mensagem_cliente = input(\"Você: \")\n",
    "        if mensagem_cliente.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
    "            print(\"\\nVendedor: Foi um prazer ajudar. Até mais!\\n\")\n",
    "            break\n",
    "\n",
    "        # Criamos uma Task que representa a \"pergunta\" do cliente\n",
    "        tarefa = Task(\n",
    "            description=f\"Cliente diz: '{mensagem_cliente}'\\n\\nResponda como um vendedor de roupas:\",\n",
    "            expected_output=\"Fornecer uma resposta apropriada de vendedor.\",\n",
    "            agent=agent,\n",
    "            # Se quiser, pode colocar tools=[...] aqui ou no agente\n",
    "        )\n",
    "\n",
    "        # Criamos um Crew com essa única task\n",
    "        crew_temporario = Crew(\n",
    "            agents=[agent],\n",
    "            tasks=[tarefa],\n",
    "            verbose=False  # Pode deixar True se quiser ver logs de debug\n",
    "        )\n",
    "\n",
    "        # Executamos a crew para obter a resposta do vendedor\n",
    "        resultado = crew_temporario.kickoff()\n",
    "\n",
    "        # O \"resultado\" final do crew será o output da última Task;\n",
    "        # podemos imprimir a resposta diretamente:\n",
    "        print(f\"\\nVendedor: {resultado.raw}\\n\")\n",
    "\n",
    "# Executar o chat\n",
    "if __name__ == \"__main__\":\n",
    "    conversa_dinamica(vendedor_roupas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
